# TF32
***WHY?***

Seriously though. We've been working on a new class of neural network
architectures for a *long* time. I do almost all my work on an M-series Mac
desktop computer, including using
[MPS](https://developer.apple.com/metal/pytorch/) for processing. Works
amazingly.

Attempting to run some of these tests on Nvidia hardware - which work
*perfectly fine* on my Mac - resulted in some horrific outcomes. Huge
differences in floating point values. Awful validation scores.

It took us an unfunny amount of time to figure out the cause of the
difference. That difference being...

## TF32

I'm going to scream. Who seriously thought a 19-bit floating point standard
with the **range** of FP32 but with a **precision** only slightly better
than FP16 is exactly what we need in machine learning?

**And who thought it was a good idea to enable this by *default*?!**

Hmm yes, what I really need for the future of machine learning is...

## TF32

Hold on... **There's dedicated hardware for these types of floating point
values?** ***A non-insignificant amount of it?*** What happens if, say, a
new awesome type of neural network enters the scene, yet requires precision
of no less than FP32?

Welp, guess all those lovely TensorCores are useless now.

I'm not sure I'm surprised honestly, given the current state of machine
learning in research and industry it was only a matter of time until
someone invented...

## TF32

We don't need any new types of neural networks. LLMs can just do everything
every model has done, is doing, and will ever do. Give up~

Just accept that we don't need precision. We don't need to try new things.
We don't need hardware that is more general, let's just make things
specific to the current trends. We just need to make...

## TF32

