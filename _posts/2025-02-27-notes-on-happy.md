# Notes on Haskell's Happy LALR(1) Parser

The main intention for this is to help students understand a few potentially
confusing things about LALR(1) parsing, in particular the one used by Happy
(which is basically Haskell's YACC). This serves as more of a collection of
notes – *mostly those I've written in Discord messages* – but it can be
anything else.

### Foreword on Terminology

Take the example
```
Exp :: {Expression}
  : Exp '+' Exp {Add $1 $3}
  | Exp '*' Exp {Mul $1 $3}
```
I'm going to use the term **production** to refer to a non-terminal block
(`Exp`) as a whole, and **expansion** to refer to each individual element of
the non-terminal block.

&nbsp;

## Braces in Production Rules are just Haskell

For anyone who might be confused about how the braces operate in Happy
production rules, for example,\
`let var '=' Exp in Exp {Let $2 $4 $6}`,\
just note that for both Alex and Happy, pretty much anything in the braces is
Haskell and is almost entirely inserted into the generated files verbatim. *Of
course* you may then argue that `$2` is not valid Haskell – *and you are
correct*, I'm hiding a lot of extra technical detail here, but this `$2` is
most likely going to be converted to `happy_var_2` in the generated file, which
is an argument passed in place of the `$2`:\
`Let happy_var_2 happy_var_4 happy_var_6`

This `$n` format just tells Happy to replace whatever is in that position with
whatever the `n`th term produces as part of a reduction. For example, with a
simple grammar that encodes Peano naturals:
```
Nat :: {Int}
  : Succ Nat {1 + $2}
  | Zero     {0     }
```
the `Zero` expansion produces literally a `0 :: Int` in the Happy-generated
function. The `Succ Nat` expansion takes the value produced by reducing `Nat`
and adds `1` to it, because `Nat` appears in the 2nd position (`$2`). When the
token sequence `Succ Succ Nat` is parsed, this performs equivalent to
`1 + 1 + 0`, which produces `2`.

If you look in the generated file, you'll find the term encased
in some other generated functions (most likely called `happyReduction_n` where
`n` is some integer). For me, that generates:
```haskell
happyReduction_2 _ =
  HappyAbsSyn4 (0)
```
where `HappyAbsSyn4 :: HappyAbsSyn` is a generated data constructor. In most
cases where we use such a parser, we wish to generate an abstract syntax tree,
and often this is done by defining custom data types. In the case of the `Let`
statement at the beginning of this section, that `Let` is a data constructor
for a certain type which is defined in a separate bit of Haskell (usually in
the postamble or in a separate imported file).

It's also important to note that **each production must produce values of the
same type**. If you look at the `Nat` example, I specify that the production
will give `Int` values, but this type declaration is optional.

### Getting Values from Tokens

When you state your tokens in Happy, you may use `$$` for certain values
contained in the token type, such as a string or integer. This is so Happy can
use these values when you do `$n` later on. This works equivalently to
pattern matching – for example you may be familiar with
```haskell
fromJust :: Maybe a
         -> a
-- Error case for `Nothing` here.
fromJust (Just x) =
  x
```
which you can view as *'extracting'* the value contained in the value of type
`Maybe a`. This is how the `$$` works in your token statements. If I have a
token data constructor `TokenVar :: String -> Token` from the data type
definition
```haskell
data Token =
  ...
  | TokenVar String
  ...
```
then the token statement `var {TokenVar $$}` performs this pattern matching by
producing a reduction that converts `var` to the string contained in the
token.

&nbsp;

## Shifting and Reducing: The Fundamentals

Depending on when you're reading this, you may already be familiar with the
terms **shift** and **reduce** in the context of parsing, specifically with
Happy. You may have also encountered a shift/reduce or reduce/reduce conflict.
It's important to know what these terms mean and the context behind the
conflicts.

### LALR Parsing and Pushdown Automata

*Look-ahead, left-to-right, rightmost derivation* (LALR) parsers are a
simplification of *left-to-right, rightmost derivation* (LR) parsers. These are
bottom-up parsers. Usually these parsers are followed by a number which states
their *look-ahead*, which is the number of tokens the parser can literally
"look ahead" in order to parse the sequence. In most cases this is LALR(1) and
LR(1). *Confusingly* both of these use look-ahead, but the primary difference
is how this look-ahead is used and certain simplifications. The reality is that
an LALR(1) parser can parse all LR(0) languages, but not all LR(1) languages.

Feel free to read more about these types of parsers and their differences, but
that's outside the scope of this post.

The important thing to note is that LALR(1) parsers – generated by Happy –
can be described with pushdown automata (PDA). For those unfamiliar or need
their memory jogged, I'm gonna use the formal definition Wikipedia defines
(since *everyone* seems to have their own way) which says a PDA is a 7-tuple

$$M=\left(Q,\,\Sigma,\,\Gamma,\,\delta,\,q_0,\,Z,\,F\right)$$

where
- $Q$ is a finite set of states.
- $\Sigma$ is a finite set called the input alphabet.
- $\Gamma$ is a finite set called the stack alphabet.
- $\delta\subseteq Q\times\left(\Sigma\cup\left\{\varepsilon\right\}\right)
  \times\Gamma\times Q\times\Gamma^*$ is a finite set called the transition
  relation.
- $q_0\in Q$ is the start state.
- $Z\in\Gamma$ is the initial stack symbol.
- $F\subseteq Q$ is the set of accepting states.

Specifically, an element of $\delta$ describes a transition
$\left(q_n,\,\sigma_a,\,\gamma_u\right)\mapsto\left(q_m,\,\gamma_{v_1}
\gamma_{v_2}\cdots\gamma_{v_t}\right)$ which
takes a current state, a current input, and current topmost stack symbol, and
produces a new state and a string to push to the stack *after* popping.

Deterministic PDAs can recognize all deterministic context-free languages,
which makes them ideal for parsers. The stack (where the term *pushdown* comes
from) is the biggest reason for this. Additionally, the stack allows the parser
to construct an abstract syntax tree (AST) directly on the stack itself.

### Shifting

In a LALR(1) parser, one of the primary actions is called **shifting**, which
is simply the action of moving the current token onto the stack. This is often
followed by a transition of state. Shifts can be described as transitions of
the form

$$\left(q_n,\,\sigma_a,\,\gamma_u\right)\mapsto\left(q_m,\,\tau\!\left(
\sigma_a\right)\right)$$

where $\tau:\Sigma\to\Gamma$ *encodes* the token as part of the stack alphabet.
This encoding is important for constructing the AST and as part of the
**reduction** operation.

### Reducing

The second primary action is called **reducing**, which pops items from the
stack, modifies them, and pushes to the stack. How this relates to PDA
operations is somewhat obscured by the fact that PDAs usually only pop *one*
item from the stack at a time. Generally a reduction operation can be thought
of as *multiple transitions* that pop *multiple items*, transitioning states
until completed. These reductions are usually written in the form

$$A\to X_1X_2\cdots X_n$$

where it replaces the **right-hand side** ($X_1X_2\cdots X_n$) on the stack
with the **left-hand side** ($A$).

The key concept here is that we're dealing with a generated pushdown automata,
and we need to consider how the stack operations influence the parsing of our
languages and construction of their ASTs.

### Shift/Reduce Conflicts

Let's use an example of a simple grammar

```
E ::= E -> E | ( E ) | C
```

where `C` is any Latin alphabet character. This grammar seems fine, but there's
an issue if we attempt to parse the sequence `A -> B -> C`. Should this be
`(A -> B) -> C` or `A -> (B -> C)`? This ambiguity causes a **shift/reduce**
conflict when using an LALR(1) parser, and we can simulate this by defining a
version of it in Happy:

```
E :: {Expression}
  : char      {Sym $1   }
  | E '->' E  {Map $1 $3}
  | '(' E ')' {$2       }
```

The terms in the braces describe the reduction to perform for that
corresponding sequence on the stack. The expansion\
`E '->' E {Map $1 $3}`\
says to reduce `E '->' E` on the stack to a `Map` value containing the two
expressions.

In parsing the sequence `'A' '->' 'B' '->' 'C'`, you see the following.\
<small><i><b>Note:</b> The top of the stack is on the right, and this is
hiding all the additional AST layers Happy uses.</i></small>

| Stack                  | Buffer                  | Next Operation |
| ---------------------- | ----------------------- | -------------- |
|                        | `'A', ->, 'B', ->, 'C'` | SHIFT          |
| `'A'`                  | `->, 'B', ->, 'C'`      | REDUCE         |
| `Sym 'A'`              | `->, 'B', ->, 'C'`      | SHIFT          |
| `Sym 'A', ->`          | `'B', ->, 'C'`          | SHIFT          |
| `Sym 'A', ->, 'B'`     | `->, 'C'`               | REDUCE         |
| `Sym 'A', ->, Sym 'B'` | `->, 'C'`               | **?**          |

but what should that next operation be? It could shift and move the `->` onto
the stack, or it could reduce\
`Sym 'A', ->, Sym 'B'` into `Map (Sym 'A') (Sym 'B')`.\
Either way we'd accept the string, but would have two different stack outputs
depending on whether we shift or reduce:

- If we *shift*, we end up with `Map (Sym 'A') (Map (Sym 'B') (Sym 'C'))`
  (`A -> (B -> C)`).
- If we *reduce*, we end up with `Map (Map (Sym 'A') (Sym 'B')) (Sym 'C')`
  (`(A -> B) -> C`).

To fix this, we need to specify which should occur, which is accomplished in
this case by defining the **associativity** of `->`.

#### A Note on Associativity

Associativity is a property of operations. Strictly speaking, a binary operator
$\star:X\times X\to X$ is associative if, for all $a,\,b,\,c\in X$

$$\left(a\star b\right)\star c=a\star\left(b\star c\right).$$

Binary operators such as integer addition ($+$) and real multiplication
($\times$) are associative, but logical implication ($\Rightarrow$) is not,
since

$$\left(p\Rightarrow q\right)\Rightarrow r\not\equiv p\Rightarrow\left(q
\Rightarrow r\right)$$

However there's a *syntactic* associativity for logical implication. This
refers to the ordering operators should be applied in if parentheses aren't
specified. Should $p\Rightarrow q\Rightarrow r$ be read as
$\left(p\Rightarrow q\right)\Rightarrow r$ or $p\Rightarrow\left(q\Rightarrow
r\right)$? The commonly-accepted convention for logical implication is that it
is **right-associative**, in this case $q\Rightarrow r$ should be read first,
meaning

$$\begin{align*}p\Rightarrow q\Rightarrow r&\equiv p\Rightarrow\left(q
\Rightarrow r\right)\\&\not\equiv\left(p\Rightarrow q\right)\Rightarrow r
\end{align*}$$

Coming back to the previous example, mapping ($\to$ *or* $\mapsto$) is commonly
right-associative, so we specify in Happy that this operator is
right-associative in the way you have seen before:

```
%right '->'
```

Now if we continue the table, this associativity rule will be applied:

| Stack                                     | Buffer    | Next Operation  |
| ----------------------------------------- | --------- | --------------- |
| ...                                       | ...       | ...             |
| `Sym 'A', ->, 'B'`                        | `->, 'C'` | REDUCE          |
| `Sym 'A', ->, Sym 'B'`                    | `->, 'C'` | SHIFT *(right)* |
| `Sym 'A', ->, Sym 'B', ->`                | `'C'`     | SHIFT           |
| `Sym 'A', ->, Sym 'B', ->, 'C'`           |           | REDUCE          |
| `Sym 'A', ->, Sym 'B', ->' Sym 'C'`       |           | REDUCE          |
| `Sym 'A', ->, Map (Sym 'B') (Sym 'C')`    |           | REDUCE          |
| `Map (Sym 'A') (Map (Sym 'B') (Sym 'C'))` |           | ACCEPT          |

Giving us a final result equivalent to `A -> (B -> C)`.

#### Precedence

Alternatively, one might have a grammar (described directly in Happy) like

```
E :: {Expression}
  : char      {Sym $1   }
  | E '+' E   {Add $1 $3}
  | E '*' E   {Mul $1 $3}
  | '(' E ')' {$2       }
```

Then, for the sequence `A * B + C`, should it be read as `(A * B) + C` or
`A * (B + C)`? This is determined by precedence, where usually an ordering is
assigned to the precedence of operators. If we say `*` has *higher* precedence
than `+`, then we'll get `(A * B) + C`. Otherwise, if we say `*` has *lower*
precedence than `+`, then we'll get `A * (B + C)`.

The precedence essentially describes the order we wish to parse something. I'm
not going to run through the full table, but you can try it for yourself and
see what happens in terms of shifts and reductions.

To set precedence of operators in Happy, you order the associativity
declarations by placing an operator of **higher** precedence *below* operators
of lower precedence. If we use common convention and say `*` has higher
precedence than `+`, we'd have

```
%left '+'
%left '*'
```

### Additional Concepts

It's important to always keep in mind how the parser "sees" the sequence and
how it uses the stack, since it's not always obvious what terms need
associativity or precedence defined. Let's use a language which has an empty
application operator, such that `AB` means applying `A` to `B`. This language
also has conditionals `?(A):B:C` which means "if `A` then `B`, otherwise `C`".\
How do we parse `?(A):B:C?(D):E:F`? Should it be `(?(A):B:C)(?(D):E:F)`?
`?(A):B:(C?(D):E:F)`? Something else?

If we assign a Happy grammar to this, we get
```
E :: {Expression}
  : char                      {Sym $1       }
  | '?' '(' E ')' ':' E ':' E {Cond $3 $6 $8}
  | E E                       {App $1 $2    }
  | '(' E ')'                 {$2           }
```
