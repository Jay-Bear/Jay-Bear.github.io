# Scaling Models, Shrinking Standards

Is this what we've come to? The so-called *pinnacle* of machine learning?
Models that spew endless strings of text, peppered with confidence and yet, so
often, utterly devoid of substance. *"...it's going to revolutionize the fie–"*
No. Stop. *Nothing* in machine learning has "revolutionized" anything since
GPT-3 and even *that* was just an overparameterized Mechanical Turk.

*Yet another* paper on large language models, because the world clearly needed
another think piece about scaling parameters from 10 billion to 100 billion.
Groundbreaking, truly. What's next? A paper proving water is wet? *"100 billion
parameters"* they say as if sheer scale alone is some kind of intellectual
flex. How avant-garde; the originality is *blinding*.

If there's one thing we *really* need next it's a **trillion** parameters doing
the exact same thing 100 billion parameters already does, but with more
**zeros**. This entire concept gives *undergraduate seminar*.

*"Pushing the boundaries of natural language processing."* The only thing
you're pushing is cloud compute budgets. There's nothing boundary-pushing about
throwing more GPUs at a bigger model. It's like chucking more glitter on some
art and calling it a masterpiece.

Size isn't **innovation**, it's **compensation**.

Congratulations, you achieved a 0.3% improvement on FOO and BAR scores. I'm
sure the world will be forever changed. How delightful to know that you can
overfit a language model to outscore others on benchmarks that barely matter
outside of Reddit debates. *So useful*. You see, the problem isn't **just**
these types of models, though their bloated architectures *are* spectacle of
inefficiency. It's this entire *ecosystem*. Endless self-congratulation over
aforementioned benchmarks which, let's face it, are about as meaningful as a
paper crown at a child's birthday party.

Your model works well, but you have no idea *why*? How utterly charming. Why
bother understanding the inner workings of your tools when you can slap a
buzzword like "**emergent properties**" on it and call it a day? Science
without theory or evidence is *guesswork*, and guesswork belongs in Las Vegas,
not 9-page conference papers.

Oh look! A half-page "discussion" on bias and environmental impact, buried at
the end like an afterthought. You've trained an unfunillion-parameter behemoth
and handwaved the energy consumption with *"future research should explore
greener training techniques"*. The gall. I do hope using more electricity than
a small town is worth it to make sure your model can autocomplete a *croque
madame* recipe with slightly fewer typos. Bravo. But no, let's all marvel at
the *bigger is better* approach while the planet sighs in dispair.

What you call a conclusion essentially boils down to *"with more money and even
more GPUs, we could go bigger"*. Oh, really? Thank you for that cutting
insight. I, for one, was deeply unaware that scaling is a problem to be solved
and its solution is... more scaling.

Unfortunately *great minds think alike*, and there are many great minds.

Triumphs of over-engineering, under-thinking, and *gloriously* misplaced
priorities. While they're sure to dazzle those at the next conference –
*assuming you pick a reasonable hoodie and running shoes* – they do little to
advance the field beyond compute the obvious.
